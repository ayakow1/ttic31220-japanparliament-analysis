{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0BjpfTibxq7a8WTEzKaoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayakow1/ttic31220-japanparliament-analysis/blob/main/NVDM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NVDM (Neural Variational Document Model)"
      ],
      "metadata": {
        "id": "tA4DoWrNESql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA1Cyckza9RL",
        "outputId": "f3af39b7-28b5-44df-b427-f36170615725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqWWRfj4a4ZI",
        "outputId": "d843db51-ba35-4dd7-c84b-62d6f948d18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nvdm' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/ysmiao/nvdm.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/YongfeiYan/Neural-Document-Modeling.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeRGHIj3bfZS",
        "outputId": "e08628da-5ed6-48c3-89bd-3594058fe737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Neural-Document-Modeling' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r Neural-Document-Modeling /content/drive/MyDrive/議事録/"
      ],
      "metadata": {
        "id": "nJcLicu3ejI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/議事録/Neural-Document-Modeling')"
      ],
      "metadata": {
        "id": "6yxBnbFcfUoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import path\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import re\n",
        "from string import punctuation\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from data_utils import read_pre_embedding\n"
      ],
      "metadata": {
        "id": "Ns9_l5X4bhgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('/content/drive/MyDrive/議事録/speech.db')"
      ],
      "metadata": {
        "id": "6VGllgy8QY9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_sql_query(f'''SELECT * FROM speech WHERE speech_date >= '2020-01-01' AND speech_date <= '2021-12-31' ''', conn)"
      ],
      "metadata": {
        "id": "iG05SkjcgmQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_sql_query(f'''SELECT * FROM speech WHERE speech_date >= '2022-01-01' AND speech_date <= '2023-04-31' ''', conn)"
      ],
      "metadata": {
        "id": "F91ZVA67Qa3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train['speech'].to_list()\n",
        "test = test['speech'].to_list()"
      ],
      "metadata": {
        "id": "JownfUiRQc0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify https://github.com/YongfeiYan/Neural-Document-Modeling/blob/master/dataset.py\n",
        "def save_dataset(save_dir, corpus, vocab):\n",
        "    \"\"\"corpus: n x all_vocab, vocab: dict of vocab trimmed(subset of all_vocab).\"\"\"\n",
        "    train, test = corpus\n",
        "    new_vocab = OrderedDict()\n",
        "    for k in vocab.keys():\n",
        "        new_vocab[k] = len(new_vocab) + 1\n",
        "    itos = {v: k for k, v in vocab.items()}\n",
        "\n",
        "    def _bow(data):\n",
        "        bow = {}  # n:f\n",
        "        wf = {}   # word word word\n",
        "        for i, j in zip(*data.nonzero()):\n",
        "            if i not in bow:\n",
        "                bow[i] = []\n",
        "            if i not in wf:\n",
        "                wf[i] = []\n",
        "            if j not in itos:\n",
        "                continue\n",
        "            f = int(data[i, j])\n",
        "            w = itos[j]\n",
        "            wf[i].extend([w] * f)\n",
        "            bow[i].append('{}:{}'.format(new_vocab[w], f))\n",
        "        bow = [' '.join(v) for v in bow.values() if len(v) > 0]\n",
        "        wf = [' '.join(v) for v in wf.values() if len(v) > 0]\n",
        "        return bow, wf\n",
        "\n",
        "    train_bow, train_txt = _bow(train)\n",
        "    test_bow, test_txt = _bow(test)\n",
        "\n",
        "    # save data\n",
        "    os.makedirs(path.join(save_dir, 'corpus'), exist_ok=True)\n",
        "\n",
        "    def _write_lines(dst, lines):\n",
        "        with open(dst, 'w') as f:\n",
        "            for line in lines:\n",
        "                f.write('{}\\n'.format(line))\n",
        "\n",
        "    _write_lines(path.join(save_dir, 'corpus/train.txt'), train_txt)\n",
        "    _write_lines(path.join(save_dir, 'corpus/test.txt'), test_txt)\n",
        "    _write_lines(path.join(save_dir, 'train.feat'), ['1 {}'.format(line) for line in train_bow])\n",
        "    _write_lines(path.join(save_dir, 'test.feat'), ['1 {}'.format(line) for line in test_bow])\n",
        "    _write_lines(path.join(save_dir, 'vocab'), ['{} {}'.format(k, v) for k, v in new_vocab.items()])\n",
        "\n",
        "    return new_vocab\n",
        "\n",
        "\n",
        "def should_filter_word(w):\n",
        "    REMOVE = r'[a-z]+'\n",
        "    return re.fullmatch(REMOVE, w) is None\n",
        "\n",
        "\n",
        "def create_data(train, test, n_vocab, save_dir):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    data = train + test\n",
        "    counter = CountVectorizer()\n",
        "    counter.fit(data)\n",
        "    vocab = counter.vocabulary_\n",
        "    cnt = counter.transform(data).sum(axis=0)\n",
        "    cnt = sorted([(k, cnt[0, vocab[k]]) for k in vocab.keys() if not should_filter_word(k)], key=lambda x: x[1])\n",
        "\n",
        "    v = {item[0]: vocab[item[0]] for item in cnt[-n_vocab:]}\n",
        "\n",
        "    train = counter.transform(train)\n",
        "    test = counter.transform(test)\n",
        "    new_vocab = save_dataset(save_dir, [train, test], v)\n",
        "    stoi = {k: v-1 for k, v in new_vocab.items()}\n",
        "\n"
      ],
      "metadata": {
        "id": "Ziyteg2neakC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "n_vocab = 4000\n",
        "save_dir = 'data/gijiroku-{}'.format(n_vocab)\n",
        "create_data(train, test, n_vocab, save_dir)\n",
        "\n",
        "print('finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuNU7LvxhFso",
        "outputId": "7bf7f1e5-7f3e-49a6-d313-bced95563319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/gijiroku-4000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh5ZaC2zj99f",
        "outputId": "e7c61e34-1534-442d-8fc9-7323c4c1142f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus\ttest.feat  train.feat  vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify https://github.com/visionshao/NVDM"
      ],
      "metadata": {
        "id": "JAaPKJfbEmEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class NVDM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_hidden, n_topic, n_sample):\n",
        "        super(NVDM, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_topic = n_topic\n",
        "        self.n_sample = n_sample\n",
        "\n",
        "        # encoder architecture\n",
        "        # encode doc to vectors\n",
        "        self.enc_vec = nn.Linear(self.vocab_size, self.n_hidden)\n",
        "        # get mean of Gaussian distribution\n",
        "        self.mean = nn.Linear(self.n_hidden, self.n_topic)\n",
        "        # get log_sigma of Gaussian distribution\n",
        "        self.log_sigma = nn.Linear(self.n_hidden, self.n_topic)\n",
        "\n",
        "        # decoder architecture\n",
        "        self.dec_vec = nn.Linear(self.n_topic, self.vocab_size)\n",
        "\n",
        "    def encoder(self, x):\n",
        "        # encode doc to vectors\n",
        "        enc_vec = F.tanh(self.enc_vec(x))\n",
        "        # getting variational parameters\n",
        "        mean = self.mean(enc_vec)\n",
        "        log_sigma = self.log_sigma(enc_vec)\n",
        "        # computing kld\n",
        "        kld = -0.5 * torch.sum(1 - torch.square(mean) + 2 * log_sigma - torch.exp(2 * log_sigma), 1)\n",
        "        return mean, log_sigma, kld\n",
        "\n",
        "    def decoder(self, mean, log_sigma, x):\n",
        "        # reconstruct doc from encoded vector\n",
        "        if self.n_sample == 1:  # single sample\n",
        "            eps = torch.rand(self.batch_size, self.n_topic)\n",
        "            doc_vec = torch.mul(torch.exp(log_sigma), eps) + mean\n",
        "            logits = F.log_softmax(self.dec_vec(doc_vec), dim=1)\n",
        "            recons_loss = -torch.sum(torch.mul(logits, x), 1)\n",
        "        # multiple samples\n",
        "        else:\n",
        "            eps = torch.rand(self.n_sample * self.batch_size, self.n_topic)\n",
        "            eps_list = list(eps.view(self.n_sample, self.batch_size, self.n_topic))\n",
        "            recons_loss_list = []\n",
        "            for i in range(self.n_sample):\n",
        "                curr_eps = eps_list[i]\n",
        "                doc_vec = torch.mul(torch.exp(log_sigma), curr_eps) + mean\n",
        "                logits = F.log_softmax(self.dec_vec(doc_vec))\n",
        "                recons_loss_list.append(-torch.sum(torch.mul(logits, x), 1))\n",
        "            recons_loss_list = torch.tensor(recons_loss_list)\n",
        "            recons_loss = torch.sum(recons_loss_list, dim=1) / self.n_sample\n",
        "\n",
        "        return recons_loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.batch_size = len(x)\n",
        "        mean, log_sigma, kld = self.encoder(x)\n",
        "        epsilons = torch.normal(0, 1, size=(\n",
        "                    x.size()[0], self.n_topic))\n",
        "        sample = (torch.exp(log_sigma) * epsilons) + mean\n",
        "        recons_loss = self.decoder(mean, log_sigma, x)\n",
        "        return sample, kld, recons_loss\n"
      ],
      "metadata": {
        "id": "Rrrm9X4ljbCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class FeatDataset(Dataset):\n",
        "\n",
        "    def __init__(self, file_path, vocab_size):\n",
        "        data, word_count = self.data_set(file_path)\n",
        "        transformed_docs = self.transform(docs=data, vocab_size=vocab_size)\n",
        "        self.data = transformed_docs\n",
        "        self.word_count = word_count\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item], self.word_count[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def data_set(self, file_path):\n",
        "        \"\"\"process data input.\"\"\"\n",
        "        data = []\n",
        "        word_count = []\n",
        "        fin = open(file_path)\n",
        "        while True:\n",
        "            line = fin.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            id_freqs = line.split()\n",
        "            doc = {}\n",
        "            count = 0\n",
        "            for id_freq in id_freqs[1:]:\n",
        "                items = id_freq.split(':')\n",
        "                # python starts from 0\n",
        "                doc[int(items[0]) - 1] = int(items[1])\n",
        "                count += int(items[1])\n",
        "            if count > 0:\n",
        "                data.append(doc)\n",
        "                word_count.append(count)\n",
        "        fin.close()\n",
        "        return data, word_count\n",
        "\n",
        "    def transform(self, docs, vocab_size):\n",
        "        \"\"\"transform data to bag-of-words\"\"\"\n",
        "        transformed_docs = []\n",
        "        for doc in docs:\n",
        "            bow_doc = np.zeros(vocab_size)\n",
        "            for word_id, freq in doc.items():\n",
        "                bow_doc[word_id] = freq\n",
        "            transformed_docs.append(bow_doc)\n",
        "\n",
        "        return transformed_docs\n"
      ],
      "metadata": {
        "id": "CXjZkh9zjzBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def test(dataloader, model):\n",
        "    loss_sum = 0.0\n",
        "    ppx_sum = 0.0\n",
        "    kld_sum = 0.0\n",
        "    word_count = 0\n",
        "    doc_count = 0\n",
        "    for data_batch, count_batch in dataloader:\n",
        "        data_batch = data_batch.float()\n",
        "        sample, kld, recons_loss = model(data_batch)\n",
        "        loss = kld + recons_loss\n",
        "        loss_sum += torch.sum(loss)\n",
        "        kld_sum += torch.mean(kld)\n",
        "        word_count += torch.sum(count_batch)\n",
        "        count_batch = torch.add(count_batch, 1e-12)\n",
        "        ppx_sum += torch.sum(torch.div(loss, count_batch))\n",
        "        doc_count += len(data_batch)\n",
        "\n",
        "    print_ppx = torch.exp(loss_sum / word_count)\n",
        "    print_ppx_perdoc = torch.exp(ppx_sum / doc_count)\n",
        "    print_kld = kld_sum / len(dataloader)\n",
        "    print('| Perplexity: {:.9f}'.format(print_ppx),\n",
        "          '| Per doc ppx: {:.5f}'.format(print_ppx_perdoc),\n",
        "          '| KLD: {:.5}'.format(print_kld))\n",
        "\n",
        "\n",
        "def train(dataloader, model, epoch_num):\n",
        "    loss_sum = 0.0\n",
        "    ppx_sum = 0.0\n",
        "    kld_sum = 0.0\n",
        "    word_count = 0\n",
        "    doc_count = 0\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    for epoch in range(epoch_num):\n",
        "        for data_batch, count_batch in dataloader:\n",
        "            data_batch = data_batch.float()\n",
        "            sample, kld, recons_loss = model(data_batch)\n",
        "            loss = kld + recons_loss\n",
        "            loss_sum += torch.sum(loss)\n",
        "            kld_sum += torch.mean(kld)\n",
        "            word_count += torch.sum(count_batch)\n",
        "            count_batch = torch.add(count_batch, 1e-12)\n",
        "            ppx_sum += torch.sum(torch.div(loss, count_batch))\n",
        "            doc_count += len(data_batch)\n",
        "            #\n",
        "            optim.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            optim.step()\n",
        "        print_ppx = torch.exp(loss_sum / word_count)\n",
        "        print_ppx_perdoc = torch.exp(ppx_sum / doc_count)\n",
        "        print_kld = kld_sum / len(dataloader)\n",
        "        print('| Epoch train: {:d} |'.format(epoch + 1),\n",
        "              '| Perplexity: {:.9f}'.format(print_ppx),\n",
        "              '| Per doc ppx: {:.5f}'.format(print_ppx_perdoc),\n",
        "              '| KLD: {:.5}'.format(print_kld))\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = 2000\n",
        "batch_size = 64\n",
        "n_hidden = 500\n",
        "n_topic = 50\n",
        "n_sample = 1\n",
        "# Dataloaders\n",
        "train_dataset = FeatDataset(r'data/gijiroku-4000/train.feat', vocab_size)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "test_dataset = FeatDataset(r'data/gijiroku-4000/test.feat', vocab_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "# Model\n",
        "model = NVDM(vocab_size, n_hidden, n_topic, n_sample)\n",
        "# Training\n",
        "train(dataloader=train_dataloader, model=model, epoch_num=30)\n",
        "# Evaluation\n",
        "model.eval()\n",
        "test(test_dataloader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdD5jYhuh6s2",
        "outputId": "b35f5350-2fca-494e-f35a-a2d8582c5e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch train: 1 | | Perplexity: 1660.499267578 | Per doc ppx: 1703.76550 | KLD: 0.062899\n",
            "| Epoch train: 2 | | Perplexity: 1266.129272461 | Per doc ppx: 1342.20459 | KLD: 0.26687\n",
            "| Epoch train: 3 | | Perplexity: 998.591552734 | Per doc ppx: 1089.50342 | KLD: 0.70759\n",
            "| Epoch train: 4 | | Perplexity: 809.885742188 | Per doc ppx: 905.25708 | KLD: 1.3437\n",
            "| Epoch train: 5 | | Perplexity: 676.040527344 | Per doc ppx: 770.29742 | KLD: 2.1103\n",
            "| Epoch train: 6 | | Perplexity: 578.771118164 | Per doc ppx: 669.42279 | KLD: 2.956\n",
            "| Epoch train: 7 | | Perplexity: 506.316955566 | Per doc ppx: 592.84583 | KLD: 3.8602\n",
            "| Epoch train: 8 | | Perplexity: 450.634124756 | Per doc ppx: 532.88696 | KLD: 4.8092\n",
            "| Epoch train: 9 | | Perplexity: 406.605133057 | Per doc ppx: 485.02399 | KLD: 5.7928\n",
            "| Epoch train: 10 | | Perplexity: 371.089172363 | Per doc ppx: 446.14313 | KLD: 6.8084\n",
            "| Epoch train: 11 | | Perplexity: 341.824249268 | Per doc ppx: 413.97357 | KLD: 7.8588\n",
            "| Epoch train: 12 | | Perplexity: 317.267456055 | Per doc ppx: 386.72159 | KLD: 8.9386\n",
            "| Epoch train: 13 | | Perplexity: 296.410339355 | Per doc ppx: 363.54050 | KLD: 10.047\n",
            "| Epoch train: 14 | | Perplexity: 278.532104492 | Per doc ppx: 343.60895 | KLD: 11.186\n",
            "| Epoch train: 15 | | Perplexity: 262.943939209 | Per doc ppx: 326.25171 | KLD: 12.351\n",
            "| Epoch train: 16 | | Perplexity: 249.298263550 | Per doc ppx: 310.95029 | KLD: 13.549\n",
            "| Epoch train: 17 | | Perplexity: 237.221466064 | Per doc ppx: 297.39230 | KLD: 14.776\n",
            "| Epoch train: 18 | | Perplexity: 226.395431519 | Per doc ppx: 285.19916 | KLD: 16.031\n",
            "| Epoch train: 19 | | Perplexity: 216.668777466 | Per doc ppx: 274.24603 | KLD: 17.312\n",
            "| Epoch train: 20 | | Perplexity: 207.866073608 | Per doc ppx: 264.34518 | KLD: 18.619\n",
            "| Epoch train: 21 | | Perplexity: 199.849868774 | Per doc ppx: 255.28580 | KLD: 19.955\n",
            "| Epoch train: 22 | | Perplexity: 192.543777466 | Per doc ppx: 247.04855 | KLD: 21.315\n",
            "| Epoch train: 23 | | Perplexity: 185.773696899 | Per doc ppx: 239.39287 | KLD: 22.699\n",
            "| Epoch train: 24 | | Perplexity: 179.551071167 | Per doc ppx: 232.34262 | KLD: 24.111\n",
            "| Epoch train: 25 | | Perplexity: 173.759368896 | Per doc ppx: 225.77856 | KLD: 25.546\n",
            "| Epoch train: 26 | | Perplexity: 168.388153076 | Per doc ppx: 219.67957 | KLD: 27.002\n",
            "| Epoch train: 27 | | Perplexity: 163.347610474 | Per doc ppx: 213.93977 | KLD: 28.477\n",
            "| Epoch train: 28 | | Perplexity: 158.631301880 | Per doc ppx: 208.57927 | KLD: 29.975\n",
            "| Epoch train: 29 | | Perplexity: 154.197494507 | Per doc ppx: 203.52353 | KLD: 31.497\n",
            "| Epoch train: 30 | | Perplexity: 150.023193359 | Per doc ppx: 198.74190 | KLD: 33.041\n",
            "| Perplexity: 202.199462891 | Per doc ppx: 252.90787 | KLD: 1.4926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/議事録/model.pt')"
      ],
      "metadata": {
        "id": "d7sN6h-LmhvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = model.dec_vec.weight.cpu().detach().T"
      ],
      "metadata": {
        "id": "48ZFTLDgsbHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, val_loader):       \n",
        "    model.eval() # set to eval mode to avoid batchnorm\n",
        "    samples = list()\n",
        "    with torch.no_grad(): # avoid calculating gradients\n",
        "        for x, _ in val_loader:\n",
        "            x = x.float()\n",
        "            sample, kld, recons_loss = model(x)\n",
        "            samples.append(sample)\n",
        "    train_repr = torch.cat(samples, dim=0).cpu().numpy()\n",
        "    return train_repr"
      ],
      "metadata": {
        "id": "uKjbltcHm4Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = pd.read_sql_query(f'''SELECT * FROM speech WHERE speech_date >= '2022-01-01' AND speech_date <= '2023-04-31' ''', conn)"
      ],
      "metadata": {
        "id": "WTBeaqeFm7yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = testdata['speech'].to_list()"
      ],
      "metadata": {
        "id": "slZR5596jZqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HwNSLuYrnKGA",
        "outputId": "12e17ff3-9ed8-4a58-9768-3eaa54497f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'質問 国会 建設業者 工事 受注 建設工事 受注 動態 統計 データ 書換え 問題 書換え GDP 値 過大 問題 前半 問題 統計データ 賃上げ 課題 お手元 資料 一月二十五日 朝日新聞 一面 統計 過大 記事 GDP 計算 材料 受注 統計 総額 元請 下請 受注 合算 数字 GDP 計算 材料 元請 受注 国交省 お答え'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repre = validate(model, test_dataloader)"
      ],
      "metadata": {
        "id": "oKO5083lnMU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repr[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZXWKv2pjAgp",
        "outputId": "4454dbe4-c59b-4409-b5a7-f46cbd1b7bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.68302435, -0.3627932 ,  0.71582747,  0.32786137, -0.14184505,\n",
              "       -0.9739588 , -1.1596297 , -1.3929586 , -0.08689603,  1.660855  ,\n",
              "       -0.22471714,  0.95406926, -1.2456349 , -0.66945314,  1.7411592 ,\n",
              "       -0.90390086, -0.31726658, -0.36820558, -0.5545904 , -1.9979192 ,\n",
              "       -0.15012038, -0.39461854,  0.35303116,  0.10400656,  0.5261552 ,\n",
              "       -0.12791753,  0.39760688, -2.0116277 ,  0.71056074, -0.714365  ,\n",
              "       -1.0988259 , -0.02518792, -0.2885734 ,  1.0826325 , -0.59357595,\n",
              "        0.63868916, -0.74680114,  1.7173587 , -1.6159464 ,  2.2673683 ,\n",
              "       -0.8096608 , -0.51813006,  1.3363781 ,  0.23885822,  0.24959758,\n",
              "       -0.9270577 ,  0.66196156,  0.90200037, -0.10782486, -0.8426756 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "6JWMcDsbrPGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3M-yuwGOrPSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}